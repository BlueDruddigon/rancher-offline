{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daac8e19-e0b1-4b1d-9ca1-1a03a9ccbd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be60f79e-6184-4bc9-b3be-aebfb900fc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from py_vncorenlp import VnCoreNLP\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, DataCollatorWithPadding, get_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ef40510-5064-40ad-aa3c-cb3cad0c87ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-30 13:41:34 INFO  WordSegmenter:24 - Loading Word Segmentation model\n"
     ]
    }
   ],
   "source": [
    "rdrsegmenter = VnCoreNLP(annotators=['wseg'], save_dir='/home/jovyan/caches/vncorenlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a8c5f49-66be-4304-a192-ac08f78d84b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '/home/jovyan/data/models/phobert-base-v2'\n",
    "MAX_SEQ_LENGTH = 256\n",
    "N_CLASSES = 11\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "N_EPOCHS = 5\n",
    "\n",
    "with open('/home/jovyan/data/datasets/PLVB/topics-classification/20250123-label2id.json') as f:\n",
    "    label2id = json.load(f)\n",
    "    \n",
    "with open('/home/jovyan/data/datasets/PLVB/topics-classification/20250123-id2label.json') as f:\n",
    "    id2label = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d6f2e4a-f15f-4400-b058-c74afa8269da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {\n",
    "    'train': '/home/jovyan/data/datasets/PLVB/topics-classification/20250123-train.parquet',\n",
    "    'val': '/home/jovyan/data/datasets/PLVB/topics-classification/20250123-val.parquet'\n",
    "}\n",
    "\n",
    "raw_dataset = load_dataset('parquet', data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e7034a5-9fe8-4cc3-8d03-dca4ea50975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3104600-1870-4a50-9804-88c463094d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8575e74b23b44445a895efa48e55eeca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17068 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "500c4f22cead475986b55d37aa78a0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1421 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def tokenize_fn(examples):\n",
    "#     # lst to store results\n",
    "#     batch_input_ids, batch_attention_mask, batch_labels = [], [], []\n",
    "\n",
    "#     # hyperparameters' configurations\n",
    "#     chunk_size = MAX_SEQ_LENGTH - 2\n",
    "#     overlap = 50\n",
    "#     stride = chunk_size - overlap\n",
    "\n",
    "#     for sentence, label in zip(examples['sentence'], examples['label']):\n",
    "#         chunks = []\n",
    "#         # tokenize the whole document to obtain tokens\n",
    "#         tokens = tokenizer.tokenize(sentence)\n",
    "\n",
    "#         # split chunks by token and convert back to string\n",
    "#         for i in range(0, len(tokens), stride):\n",
    "#             chunk = tokens[i:i+chunk_size]\n",
    "#             chunks.append(tokenizer.convert_tokens_to_string(chunk))\n",
    "\n",
    "#         # tokenizing all chunks\n",
    "#         encodings = tokenizer(\n",
    "#             chunks,\n",
    "#             padding='max_length',\n",
    "#             max_length=MAX_SEQ_LENGTH,\n",
    "#             truncation=True,\n",
    "#             return_tensors='pt'\n",
    "#         )\n",
    "\n",
    "#         batch_input_ids.append(encodings['input_ids'])\n",
    "#         batch_attention_mask.append(encodings['attention_mask'])\n",
    "\n",
    "#         # convert raw label to one-hot encoding then store\n",
    "#         label = F.one_hot(torch.tensor(label), num_classes=N_CLASSES)\n",
    "#         batch_labels.append(label)\n",
    "    \n",
    "#     # padding for varying number of chunks\n",
    "#     max_num_chunks = max(x.size(0) for x in batch_input_ids)\n",
    "#     padded_input_ids, padded_attention_mask = [], []\n",
    "#     for input_ids, attention_mask in zip(batch_input_ids, batch_attention_mask):\n",
    "#         pad_len = max_num_chunks - input_ids.size(0)\n",
    "#         if pad_len > 0:\n",
    "#             input_ids = torch.cat([input_ids, torch.zeros([pad_len, MAX_SEQ_LENGTH], dtype=torch.long)], dim=0)\n",
    "#             attention_mask = torch.cat([attention_mask, torch.zeros([pad_len, MAX_SEQ_LENGTH], dtype=torch.long)], dim=0)\n",
    "#         padded_input_ids.append(input_ids)\n",
    "#         padded_attention_mask.append(attention_mask)\n",
    "\n",
    "#     # stack into final tensor\n",
    "#     batch_input_ids = torch.stack(padded_input_ids)\n",
    "#     batch_attention_mask = torch.stack(padded_attention_mask)\n",
    "\n",
    "#     return {\n",
    "#         'input_ids': batch_input_ids,\n",
    "#         'attention_mask': batch_attention_mask,\n",
    "#         'labels': torch.stack(batch_labels)\n",
    "#     }\n",
    "\n",
    "# encoded_dataset = raw_dataset.map(tokenize_fn, batched=True, remove_columns=['_id', 'sentence', 'label'], batch_size=100)\n",
    "# encoded_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "def tokenize_fn(example):\n",
    "    \"\"\"Process a single example without padding\"\"\"\n",
    "    chunk_size = MAX_SEQ_LENGTH - 2\n",
    "    overlap = 50\n",
    "    stride = chunk_size - overlap\n",
    "    \n",
    "    # Tokenize the sentence\n",
    "    tokens = tokenizer.tokenize(example['sentence'])\n",
    "    \n",
    "    # Create chunks\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), stride):\n",
    "        chunk = tokens[i:i+chunk_size]\n",
    "        if chunk:  # Only add non-empty chunks\n",
    "            chunks.append(tokenizer.convert_tokens_to_string(chunk))\n",
    "    \n",
    "    # Tokenize all chunks\n",
    "    if chunks:\n",
    "        encodings = tokenizer(\n",
    "            chunks,\n",
    "            padding='max_length',\n",
    "            max_length=MAX_SEQ_LENGTH,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = encodings['input_ids']\n",
    "        attention_mask = encodings['attention_mask']\n",
    "    else:\n",
    "        # Handle empty documents with a single zero chunk\n",
    "        input_ids = torch.zeros((1, MAX_SEQ_LENGTH), dtype=torch.long)\n",
    "        attention_mask = torch.zeros((1, MAX_SEQ_LENGTH), dtype=torch.long)\n",
    "    \n",
    "    # Create label tensor\n",
    "    label = F.one_hot(torch.tensor(example['label']), num_classes=11)\n",
    "    \n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'labels': label\n",
    "    }\n",
    "\n",
    "# Apply the tokenization function to the dataset\n",
    "encoded_dataset = raw_dataset.map(\n",
    "    tokenize_fn,\n",
    "    batched=False,\n",
    "    remove_columns=['_id', 'sentence', 'label'],\n",
    ")\n",
    "\n",
    "# Set the format to PyTorch tensors\n",
    "encoded_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abac80ca-2d24-43f4-91f9-4575f36b14dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to pad sequences in a batch to the same length\n",
    "    \"\"\"\n",
    "    # Find max number of chunks in this batch\n",
    "    max_chunks = max(x['input_ids'].size(0) for x in batch)\n",
    "    \n",
    "    # Lists to store padded tensors\n",
    "    batch_input_ids = []\n",
    "    batch_attention_masks = []\n",
    "    batch_labels = []\n",
    "    \n",
    "    # Pad each example to max_chunks\n",
    "    for example in batch:\n",
    "        input_ids = example['input_ids']\n",
    "        attention_mask = example['attention_mask']\n",
    "        current_chunks = input_ids.size(0)\n",
    "        \n",
    "        # Calculate padding needed\n",
    "        pad_chunks = max_chunks - current_chunks\n",
    "        \n",
    "        if pad_chunks > 0:\n",
    "            # Create padding tensors\n",
    "            input_pad = torch.zeros(pad_chunks, MAX_SEQ_LENGTH, dtype=torch.long)\n",
    "            mask_pad = torch.zeros(pad_chunks, MAX_SEQ_LENGTH, dtype=torch.long)\n",
    "            \n",
    "            # Add padding\n",
    "            input_ids = torch.cat([input_ids, input_pad], dim=0)\n",
    "            attention_mask = torch.cat([attention_mask, mask_pad], dim=0)\n",
    "        \n",
    "        batch_input_ids.append(input_ids)\n",
    "        batch_attention_masks.append(attention_mask)\n",
    "        batch_labels.append(example['labels'])\n",
    "    \n",
    "    # Stack all tensors\n",
    "    return {\n",
    "        'input_ids': torch.stack(batch_input_ids),\n",
    "        'attention_mask': torch.stack(batch_attention_masks),\n",
    "        'labels': torch.stack(batch_labels)\n",
    "    }\n",
    "\n",
    "train_loader = DataLoader(encoded_dataset['train'], batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(encoded_dataset['val'], batch_size=16, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "539c76e5-395b-42fd-a7bd-c8fe25e0aad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = AutoModel.from_pretrained(MODEL_PATH)\n",
    "        self.aggregator = nn.MultiheadAttention(embed_dim=768, num_heads=8, dropout=0.1, batch_first=True)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(768, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(768, num_labels)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        batch_size, num_chunks, seq_length = input_ids.size()\n",
    "        \n",
    "        # Reshape for processing all chunks\n",
    "        flat_input_ids = input_ids.view(-1, seq_length)\n",
    "        flat_attention_mask = attention_mask.view(-1, seq_length)\n",
    "        \n",
    "        # Get PhoBERT encodings for all chunks\n",
    "        outputs = self.encoder(\n",
    "            input_ids=flat_input_ids,\n",
    "            attention_mask=flat_attention_mask\n",
    "        )\n",
    "        \n",
    "        # Get CLS token representations for each chunk\n",
    "        chunk_encodings = outputs.last_hidden_state[:, 0]  # Use CLS token\n",
    "        chunk_encodings = chunk_encodings.view(batch_size, num_chunks, -1)\n",
    "        \n",
    "        # Create chunk-level attention mask (1 if chunk exists, 0 if padding)\n",
    "        chunk_mask = (attention_mask.sum(dim=-1) > 0)\n",
    "        \n",
    "        # Convert boolean mask to float mask where False = -inf, True = 0.0\n",
    "        attn_mask = torch.zeros_like(chunk_mask, dtype=torch.float)\n",
    "        attn_mask.masked_fill_(~chunk_mask, float('-inf'))\n",
    "        \n",
    "        # Aggregate chunk encodings using multi-head attention\n",
    "        # Using self-attention: query, key, and value are all chunk_encodings\n",
    "        doc_encoding, _ = self.chunk_attention(\n",
    "            query=chunk_encodings,\n",
    "            key=chunk_encodings,\n",
    "            value=chunk_encodings,\n",
    "            key_padding_mask=~chunk_mask  # PyTorch expects mask to be False for valid positions\n",
    "        )\n",
    "        \n",
    "        # Pool the attention outputs to get document representation\n",
    "        # Use the mask to get mean of non-padded chunks\n",
    "        mask_expanded = chunk_mask.unsqueeze(-1).float()\n",
    "        doc_encoding = (doc_encoding * mask_expanded).sum(dim=1) / mask_expanded.sum(dim=1).clamp(min=1e-9)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(doc_encoding)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17d0ffd4-50db-4e60-a268-5c7786f50fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at /home/jovyan/data/models/phobert-base-v2 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Classifier(11)\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
    "num_training_steps = N_EPOCHS * len(train_loader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name='cosine_with_restarts', optimizer=optimizer, num_warmup_steps=50, num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03385877-a37c-48f9-bf47-6f8f47d94d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6f2b60cbe847fb898370bde917736b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[[    0,    20,  8859,  ...,  2325,  6692,     2],\n",
      "         [    0,   292,     4,  ...,  8917,  2665,     2],\n",
      "         [    0,    12,  1391,  ...,     1,     1,     1],\n",
      "         ...,\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[    0,   404,  7068,  ...,    11,   369,     2],\n",
      "         [    0,    11,  2488,  ..., 12123,  1986,     2],\n",
      "         [    0,   556,  4253,  ...,    39,  7068,     2],\n",
      "         ...,\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[    0, 42680,   605,  ...,     1,     1,     1],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         ...,\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    0,  1144,  5232,  ...,    82,   100,     2],\n",
      "         [    0,  1648,     9,  ...,   355,    53,     2],\n",
      "         [    0,  2926, 11811,  ...,    16, 18608,     2],\n",
      "         ...,\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[    0,  3507,   136,  ...,   124,  7157,     2],\n",
      "         [    0,  3664,     5,  ...,     1,     1,     1],\n",
      "         [    0,  2858, 10138,  ...,     1,     1,     1],\n",
      "         ...,\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[    0,  8284,  7665,  ...,     1,     1,     1],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         ...,\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]]), 'labels': tensor([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]])}\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(train_loader, total=num_training_steps)\n",
    "\n",
    "for index, batch in enumerate(pbar):\n",
    "    if index == 0:\n",
    "        print(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01d8fd8368a24f1ca8e5726f4d71a341": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "048b8cc8bb954c6b82f445994d3e5cfc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_b1bd37a13ab0425b8b2babd32cfa9933",
       "max": 1421,
       "style": "IPY_MODEL_3b867ee11bfa4fba9f59c32c75133563",
       "value": 1421
      }
     },
     "05600e9764474e118246d3437197fc73": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0930e019fc594aa3beabc57f39623f28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d1065d01fac044d495e8147c1cc69c70",
       "style": "IPY_MODEL_e77d1e3e9dc14fc481151350c8052d13",
       "value": " 0/5335 [00:00&lt;?, ?it/s]"
      }
     },
     "0b62ff77730f415c90a6ca8e6dd5a3e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0c23008bdc664eb888ca73898e958b84": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_ea432dc220794dc8802525e0f7ec7cb8",
       "max": 5335,
       "style": "IPY_MODEL_f18397ef565245d18b434c6e6b16ca85"
      }
     },
     "15d2d865c14343c0bcc803eae2eb4f57": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_dda0fdb5cc394f1aa02370a120abb12b",
       "style": "IPY_MODEL_258953b121c542479465f6b8cdd98fef",
       "value": " 5335/5335 [00:00&lt;00:00, 183284.15it/s]"
      }
     },
     "1775897f2c1d4c49a5c6788a8b6e4804": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1917955b4c404308ac191cd74ca15339": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_5634f124c13d4c509c276bdb72783c14",
       "style": "IPY_MODEL_f4d179536b8245cca145db37733d0a54",
       "value": " 17068/17068 [01:43&lt;00:00, 144.71 examples/s]"
      }
     },
     "1f48db320d3e4cf8a0adcfbb6bad3811": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "23fe028995a44995bff8cf05b04adbef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2461503560b3487193ef243ae82492d6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "258953b121c542479465f6b8cdd98fef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2ad63018fa214b1c99a807f260f6c9d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2d7e6d6418d14bc2a842231027aa4ad8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "31f1aaaf77b149468239f5f7dc216d21": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "33db93f69bdb48f2a0910b3432cd4114": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_be9a1c3dfa8f437b9d4448fd1b18a86d",
       "style": "IPY_MODEL_d8bd6956530d440c9a4bdb4891d590eb",
       "value": "100%"
      }
     },
     "3b867ee11bfa4fba9f59c32c75133563": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4824ab28b1d345158413c43016bfacc9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "483b739f60914ac2a04ba6d46a257f63": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d455892129084d1aab4b7f7fcc0d01b4",
       "style": "IPY_MODEL_23fe028995a44995bff8cf05b04adbef",
       "value": "Map: 100%"
      }
     },
     "4924336db3bc429fae807281bc3ce502": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4b02737c38a14681a95f07a736fd1b5f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4cbd4c58241442c48b044f02af31c417": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d90f9050374e43cc83087a803a9c57b3",
       "style": "IPY_MODEL_a63c7925bb6344de95b4e33751f57aed",
       "value": " 1421/1421 [00:09&lt;00:00, 130.51 examples/s]"
      }
     },
     "4d6f2b60cbe847fb898370bde917736b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_dfdcb792744a46f2a2ece95d720822fe",
        "IPY_MODEL_fe0c6b2f1fbd4beaaa9d96383b6e37c6",
        "IPY_MODEL_da32baae90e8487ca926b93ec74e7696"
       ],
       "layout": "IPY_MODEL_f99ad06f48ed4a199ed33b9e1d115277"
      }
     },
     "500c4f22cead475986b55d37aa78a0bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_7f151f48efe0435b822a03339e11ba3c",
        "IPY_MODEL_c9d12357249240c7ace8c512c9a203fa",
        "IPY_MODEL_a1e72833595d4824becfcee7c0f42fe6"
       ],
       "layout": "IPY_MODEL_a1ccd508fc004842a93839a26b576be8"
      }
     },
     "50707e9dba9b4311a4b3d730fce54c10": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5634f124c13d4c509c276bdb72783c14": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "599e19a638354906afd5631463504cbd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_c04cfc34bc2f4286942e18fa83066155",
       "max": 17068,
       "style": "IPY_MODEL_d80bae251927406685adf4ca9afc38da",
       "value": 17068
      }
     },
     "59cd9730c42641469bc9650b0b483fd3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5a652e4892aa4705995262ec553ebe4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6055ab5d161c4ac2a01d92902ee1f170": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "619bb53d15634c92a022eddfe43819bc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "65aa9b11870446a48fc3b5bbd4bbe179": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "720a9b22ec4d4626a91bc2531fcc1746": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7237e805a98a4ceba05c0f84fd95a222": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "76b54d4747e346c9b231b379c14dcd4c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7c87697e4154462da36c7dd3dc4e95a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_ff345a07b1b044f6915cc03caed98f0c",
        "IPY_MODEL_0c23008bdc664eb888ca73898e958b84",
        "IPY_MODEL_0930e019fc594aa3beabc57f39623f28"
       ],
       "layout": "IPY_MODEL_ae12101ee38c49bdb609b2238a163858"
      }
     },
     "7f151f48efe0435b822a03339e11ba3c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_619bb53d15634c92a022eddfe43819bc",
       "style": "IPY_MODEL_8b41e9e7dd4f471da18f2da33c66bdc8",
       "value": "Map: 100%"
      }
     },
     "8462d6b39f9b4a1db66bfca8a28d6299": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a6726a762d1a4384b9ae7e6198d206e6",
       "style": "IPY_MODEL_c57db319e2c54187b9e517bf7c271695",
       "value": " 17068/17068 [01:44&lt;00:00, 169.12 examples/s]"
      }
     },
     "8575e74b23b44445a895efa48e55eeca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_e46e833c931444c4990e660b7c92ba74",
        "IPY_MODEL_cc2808d301bb41c98b497f63cbd99630",
        "IPY_MODEL_1917955b4c404308ac191cd74ca15339"
       ],
       "layout": "IPY_MODEL_a470269e88384ae2949eca91010cea18"
      }
     },
     "8b41e9e7dd4f471da18f2da33c66bdc8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8f8500c9ca6a46bcbafdacb785d15cac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_fc39bf2661be4c88b383e8b22f610a6e",
       "style": "IPY_MODEL_01d8fd8368a24f1ca8e5726f4d71a341",
       "value": "Map: 100%"
      }
     },
     "970c9364660142b3989fe67ed07b75d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4924336db3bc429fae807281bc3ce502",
       "style": "IPY_MODEL_7237e805a98a4ceba05c0f84fd95a222",
       "value": "  0%"
      }
     },
     "9725ceb299684c3cb9dbd1bc5c22a85c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9f0534be5b8945a997f6ed6365ed0222": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_da72c04e7111454781b0507526a1b6fa",
        "IPY_MODEL_edf819f888274514b811d9a399ed27d2",
        "IPY_MODEL_e8f44038fbd4408786dec24bcee091f0"
       ],
       "layout": "IPY_MODEL_fac1ba7f0c1a478ebd441014850f9741"
      }
     },
     "9f5198f23a5044bd8535ff5931b33805": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_8f8500c9ca6a46bcbafdacb785d15cac",
        "IPY_MODEL_048b8cc8bb954c6b82f445994d3e5cfc",
        "IPY_MODEL_4cbd4c58241442c48b044f02af31c417"
       ],
       "layout": "IPY_MODEL_a53d5ce69f2741b18d63353d68e29aed"
      }
     },
     "9f5b879765a04c44a069b2f390d863d2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a15e839c1bf64953ad25c140da0f0c5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_af8998125fa74eada54e56afbb930d3c",
       "style": "IPY_MODEL_c47dd63c2c93444eae6ad6cc381080e1",
       "value": " 0/5335 [00:00&lt;?, ?it/s]"
      }
     },
     "a1ccd508fc004842a93839a26b576be8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a1e72833595d4824becfcee7c0f42fe6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_eb3e71d93bb642fd8a7c58c0643f960e",
       "style": "IPY_MODEL_2ad63018fa214b1c99a807f260f6c9d4",
       "value": " 1421/1421 [00:09&lt;00:00, 166.45 examples/s]"
      }
     },
     "a32e75a33b7249e5a217bd2515e066fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a470269e88384ae2949eca91010cea18": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a53d5ce69f2741b18d63353d68e29aed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a562d0adf88d4625adce90ff6fe2ce42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_970c9364660142b3989fe67ed07b75d2",
        "IPY_MODEL_e580d32812d048a89c99a4a4475d74b0",
        "IPY_MODEL_a15e839c1bf64953ad25c140da0f0c5b"
       ],
       "layout": "IPY_MODEL_59cd9730c42641469bc9650b0b483fd3"
      }
     },
     "a63c7925bb6344de95b4e33751f57aed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a6726a762d1a4384b9ae7e6198d206e6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ad78fdbd9e89497daead60977e3e0f8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ae12101ee38c49bdb609b2238a163858": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "af8998125fa74eada54e56afbb930d3c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b1bd37a13ab0425b8b2babd32cfa9933": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b4f3883c6d284a69b3740b58a10ca384": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_c8b2da766a134b7db8fe0465538d9dc4",
       "max": 5335,
       "style": "IPY_MODEL_dd169b10c54c469db82ba40610ace1d0",
       "value": 5335
      }
     },
     "b5f821d0218b47acae562e8bb521cda5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_33db93f69bdb48f2a0910b3432cd4114",
        "IPY_MODEL_b4f3883c6d284a69b3740b58a10ca384",
        "IPY_MODEL_15d2d865c14343c0bcc803eae2eb4f57"
       ],
       "layout": "IPY_MODEL_720a9b22ec4d4626a91bc2531fcc1746"
      }
     },
     "be9a1c3dfa8f437b9d4448fd1b18a86d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c04cfc34bc2f4286942e18fa83066155": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c47dd63c2c93444eae6ad6cc381080e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c57db319e2c54187b9e517bf7c271695": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c89cb0fa9fbc4cc48cb03de5a5d6d396": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c8b2da766a134b7db8fe0465538d9dc4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c9d12357249240c7ace8c512c9a203fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_50707e9dba9b4311a4b3d730fce54c10",
       "max": 1421,
       "style": "IPY_MODEL_e584abdeb042453db880b4c360b1c00a",
       "value": 1421
      }
     },
     "cbacd22b44e2424685148f3754da3620": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cc2808d301bb41c98b497f63cbd99630": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_db5e4d4b3e3a49ccb135730988698f7b",
       "max": 17068,
       "style": "IPY_MODEL_4b02737c38a14681a95f07a736fd1b5f",
       "value": 17068
      }
     },
     "d1065d01fac044d495e8147c1cc69c70": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d455892129084d1aab4b7f7fcc0d01b4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d5f2f4cebc0e4db8b8f0d3d9f61c91f8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d80bae251927406685adf4ca9afc38da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d8bd6956530d440c9a4bdb4891d590eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d90f9050374e43cc83087a803a9c57b3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "da32baae90e8487ca926b93ec74e7696": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c89cb0fa9fbc4cc48cb03de5a5d6d396",
       "style": "IPY_MODEL_cbacd22b44e2424685148f3754da3620",
       "value": " 1067/5335 [00:03&lt;00:12, 337.87it/s]"
      }
     },
     "da72c04e7111454781b0507526a1b6fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2d7e6d6418d14bc2a842231027aa4ad8",
       "style": "IPY_MODEL_9725ceb299684c3cb9dbd1bc5c22a85c",
       "value": "Map:   0%"
      }
     },
     "db5e4d4b3e3a49ccb135730988698f7b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "dd169b10c54c469db82ba40610ace1d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "dda0fdb5cc394f1aa02370a120abb12b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "dfdcb792744a46f2a2ece95d720822fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d5f2f4cebc0e4db8b8f0d3d9f61c91f8",
       "style": "IPY_MODEL_4824ab28b1d345158413c43016bfacc9",
       "value": " 20%"
      }
     },
     "e46e833c931444c4990e660b7c92ba74": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_31f1aaaf77b149468239f5f7dc216d21",
       "style": "IPY_MODEL_65aa9b11870446a48fc3b5bbd4bbe179",
       "value": "Map: 100%"
      }
     },
     "e4bad1956abd46e39061bad527973cbd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_483b739f60914ac2a04ba6d46a257f63",
        "IPY_MODEL_599e19a638354906afd5631463504cbd",
        "IPY_MODEL_8462d6b39f9b4a1db66bfca8a28d6299"
       ],
       "layout": "IPY_MODEL_05600e9764474e118246d3437197fc73"
      }
     },
     "e580d32812d048a89c99a4a4475d74b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_2461503560b3487193ef243ae82492d6",
       "max": 5335,
       "style": "IPY_MODEL_5a652e4892aa4705995262ec553ebe4e"
      }
     },
     "e584abdeb042453db880b4c360b1c00a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e77d1e3e9dc14fc481151350c8052d13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e8f44038fbd4408786dec24bcee091f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_0b62ff77730f415c90a6ca8e6dd5a3e3",
       "style": "IPY_MODEL_1775897f2c1d4c49a5c6788a8b6e4804",
       "value": " 0/17068 [00:00&lt;?, ? examples/s]"
      }
     },
     "ea432dc220794dc8802525e0f7ec7cb8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "eb3e71d93bb642fd8a7c58c0643f960e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "edf819f888274514b811d9a399ed27d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_9f5b879765a04c44a069b2f390d863d2",
       "max": 17068,
       "style": "IPY_MODEL_ad78fdbd9e89497daead60977e3e0f8b"
      }
     },
     "f18397ef565245d18b434c6e6b16ca85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f4d179536b8245cca145db37733d0a54": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f99ad06f48ed4a199ed33b9e1d115277": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fac1ba7f0c1a478ebd441014850f9741": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fc39bf2661be4c88b383e8b22f610a6e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fe0c6b2f1fbd4beaaa9d96383b6e37c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_76b54d4747e346c9b231b379c14dcd4c",
       "max": 5335,
       "style": "IPY_MODEL_6055ab5d161c4ac2a01d92902ee1f170",
       "value": 1067
      }
     },
     "ff345a07b1b044f6915cc03caed98f0c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1f48db320d3e4cf8a0adcfbb6bad3811",
       "style": "IPY_MODEL_a32e75a33b7249e5a217bd2515e066fa",
       "value": "  0%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
